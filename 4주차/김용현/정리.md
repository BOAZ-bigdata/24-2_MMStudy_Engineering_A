# 정리

<img src = "https://velog.velcdn.com/images/cksgodl/post/76b3fe73-0455-4d66-b5b0-974110bb0b23/image.png" width = 80% height = "80%">

### 카프카에 메세지를 쓰는 과정
1. ProducerRecord 객체 생성 -> 토픽, 밸류 지정 필수 / 키, 파티션 지정 선택
2. 데이터 바이트 배열로 직렬화
3. 파티셔너에게 데이터를 보내 파티션 결정(보통 ProducerRecord 객체의 키 값으로 결정)
4. 같은 토픽 파티션으로 전송될 레코드들을 모은 레코드 배치에 추가
5. 별도의 스레드가 카프카 브로커에 전송
6. 메시지를 받은 브로커에서 성공 정보를 담아 RecordMetadata 객체 리턴
7. 오류 시 에러 리턴

### 3.5.3 카프카에서 에이브로 레코드 사용하기
기본적으로는 에이브로 파일에 전체 스키마를 저장한다고 했다. 그러나 카프카에서는 레코드 사이즈를 줄이기 위해 **스키마 레지스트리**라는 아키텍처 패턴을 사용한다. 

![alt text](image-6.png)  
다음은 스키마 레지스트리 아키텍처를 그림으로 표현한 것이다.

패턴을 설명하면,  
- 모든 스키마를 스키마 레지스트리에 저장한다.
- 레코드에는 스키마 전체가 아닌 스키마 식별용 고유 식별자를 집어넣는다.
- 역직렬화 시 고유 식별자를 보고 스키마를 스키마 레지스트리에서 가져와 사용한다.

다음과 같다.

실제 구현 시에는 `KafkaAvroSerializer`를 사용하며 KafkaProducer 객체 생성 시 전달하는 Properties 객체 초기화 시 `schema.registry.url` 값에 스키마 레지스트리 경로를 넣는다.

레코드의 타입으로는 POJO는 사용 불가하며 에이브로의 코드 생성 기능을 통해 생성된 에이브로 객체만 올 수 있다.

또한 제네릭 에이브로 객체(`GenericRecord`)도 사용할 수 있는데, 이 경우 스키마 정보만 넘겨주고 
```java
//중략

GenericRecord customer = new GenericData.Record(schema);
customer.put("id", "nCustomers");
customer.put("name", "name");
customer.put("email", "email");

ProducerRecord<String, GenericRecord> data = new ProducerRecord<>("customerContacts", name, customer)
producer.send(data)
```
다음과 같이 레코드의 값들을 초기화하여 사용할 수 있다.

## 4.1.2 컨슈머 그룹과 파티션 리밸런스
토픽에 새로운 파티션이 추가되거나 컨슈머가 추가되는 경우 등 변동이 발생했을 경우 **파티션 리밸런스**를 진행한다.

### 조급한 리밸런스
모든 컨슈머가 자신이 담당하고 있는 파티션을 포기하고 파티션을 포기한 컨슈머 모두가 다시 그룹에 참여한 뒤 새로운 파티션을 할당받아 읽기 작업을 하는 방식

### 협력적(점진적) 리밸런스
전부 파티션을 포기하지 않고 재할당이 필요한 컨슈머만 파티션 소유권을 포기하여 리밸런싱 하는 방식 

---

컨슈머는 그룹 코디네이터로 지정된 컨슈머에게 주기적으로 하트비트를 전송함으로써 소속 여부와 할당된 파티션에 대한 소유권을 유지한다.

컨슈머가 일정 시간 하트비트를 보내지 않는다면, 코디네이터는 해당 컨슈머가 죽었다고 판단하고 리밸런스를 실행한다. 

> **참고**
> 버전 3.1 이후로는 리밸런스 기본 값이 조급한 리밸런스에서 협력적 리밸런스로 바뀌었다고 한다. 조급한 리밸런스는 추후 삭제될 예정이다.

## 4.6 오프셋과 커밋
카프카에 특수 토픽인 `__consumer_offsets` 토픽에 각 파티션 별 커밋된 오프셋을 업데이트하도록 하는 메시지를 보냄으로써 오프셋 커밋이 이루어진다. 

> **참고**  
> 커밋은 poll() 메소드가 리턴한 마지막 오프셋 바로 다음 오프셋이 커밋된다.

### 4.6.1 자동 커밋
5초 간격이 기본 값으로 5초마다 컨슈머는 poll() 호출 시 마지막 오프셋 위치를 커밋한다. 그러나 5초 안에 컨슈머가 크래시 나서 리밸런스가 진행되거나 한다면 새로운 컨슈머는 커밋 위치부터 다시 데이터를 처리하기 때문에 데이터 중복 처리가 충분히 일어날 수 있다.

### 4.6.2 현재 오프셋 커밋하기
`enable.auto.commit=false`를 통해 자동 커밋 기능을 끄고, `commitSync()` 메소드를 이용해 명시적으로 오프셋 커밋을 수행할 수 있다.

이 때에도 동일하게 poll()에 의해 리턴된 마지막 오프셋을 저장한다.

### 4.6.3 비동기적 커밋
`commitAsync()` 메소드를 통해 실행할 수 있으며, 위의 `commitSync()`와는 다르게 비동기로 동작한다.

발생할 수 있는 문제는, 비동기기 때문에 요청을 하고 응답을 받은 시점에 이미 다른 커밋이 성공했을 수도 있다. 이때 이전 요청이 실패하여 재시도 후 커밋을 성공한다면 커밋이 다시 뒤로 돌아가는 상황이 벌어질 수도 있다.

### 4.6.4 동기, 비동기 커밋 같이 사용하기
정상적인 상황 -> `commitAsync()` 사용
컨슈머를 닫는 상황 -> `commitSync()` 사용

### 4.6.5 특정 오프셋 커밋하기
`commitSync()`, `commitAsync()` 메소드를 호출할 때 인수로 커밋하고자 하는 파티션과 오프셋의 맵을 전달하여 특정 오프셋을 커밋할 수 있다.

docker-compose.yml 환경 변수 설정 설명 참고 자료
https://taaewoo.tistory.com/59  
https://medium.com/mo-zza/kafka-kraft-%EB%AA%A8%EB%93%9C-with-docker-%EB%8F%99%EB%AC%BC%EC%9B%90%EC%9D%84-%ED%83%88%EC%B6%9C%ED%95%9C-kafka-8b5e7c7632fa