# 4장 카프카 컨슈머: 카프카에서 데이터 읽기
카프카에서 데이터를 읽는 애플리케이션은 토픽을 구독하고 구독한 토픽들로부터 메시지를 받기 위해 KafkaConsumer를 사용

카프카에서의 데이터를 읽는 것은 다른 메시지 전달 시스템과는 조금 다르다.

## 카프카 컨슈머와 컨슈머 그룹
토픽으로부터 데이터를 읽어 오는 작업을 확장할 수 있어야 한다. 여러 개의 프로듀서가 동일한 토픽에 메시지를 쓰듯이 여러 개의 컨슈머가 같은 토픽으로부터 데이터를 분할해서 읽어올 수 있게 해야 함

어떻게 확장?
-> 컨슈머 그룹에 컨슈머를 추가하며 카프카 토픽에서 읽어오는 데이터 양을 확장한다.

한 애플리케이션의 규모를 확장하기 위해 컨슈머 수를 늘리는 경우 이외에도 여러 애플리케이션이 동일한 토픽에서 데이터를 읽어와야 하는 경우 역시 흔하다.

이런 경우 각각 애플리케이션이 전체 메시지의 일부만 받는 게 아니라 전부 다 받도록 해야 함.

![Untitled](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C2UfOwDKtP8Aq1jRBiuzJw.png)

핵심 요약
    
    - 1개 이상의 토픽에 대해 모든 메시지를 받아야하는 애플리케이션 별로 새로운 컨슈머 그룹을 생성한다. 
    토픽에서 메시지를 읽거나 처리하는 규모 확장을 위해서 이미 존재하는 컨슈머 그룹에 새로운 컨슈머를 추가하여 해당 그룹 내의 컨슈머 각각이 메시지의 일부만을 받아서 처리하도록 한다.


## 컨슈머 그룹과 파티션 리밸런스
컨슈머에 할당된 파티션을 다른 컨슈머에게 할당해주는 작업을 '리밸런스'라고 한다. 리밸런스는 컨슈머 그룹에 높은 가용성과 규모 가변성을 제공하는 기능이기 때문에 중요하지만, 문제없이 작업이 수행되고 있는 와중이라면 그리 달갑지 않지.

### 조급한 리밸런스

조급한 리밸런스가 실행되는 와중에 모든 컨슈머는 읽기 작업을 멈추고 자신에게 할당된 파티션에 대한 소유권을 포기하고 컨슈머 그룹에 다시 참여하여 새로운 파티션 할당을 받는다.

-> 근본적으로 전체 컨슈머 그룹에 대해 짧은 시간 동안 작업을 멈추게 한다.

### 협력적 리밸런스
한 컨슈머에게 할당되어 있던 파티션만을 다른 컨슈머에 재할당한다. 재할당되지 않은 파티션에서 레코드를 읽어서 처리하던 컨슈머들은 작업에 방해 받지 않고 하던 일을 계속 한다.

컨슈머는 해당 컨슈머 그룹의 그룹 코디네이터 역할을 지정받은 카프카 브로커에 하트비트를 전송함으로써 소유권을 유지

일정시간 하트비트를 전송하지 않으면 해당 컨슈머가 죽었다고 생각하여 리밸런스를 실행한다.

## 카프카 컨슈머 생성하기
 카프카 레코드를 읽어오기 위해서는 : KafkaConsumer 인스턴스를 생성한다.

 꼭 지정해야하는 속성 3개
 1. bootstrap.server
 2. key.deserializer
 3. value.deserializer

첫 번째 속성은 프로듀서와 동일하고, 나머지 두개는 프로듀서의 시리얼라이저와 비슷하지만 자바 객체를 바이트 배열로 변환하는 클래스를 지정하는 것이 아니라 `바이트 배열을 자바 객체로 변화하는 클래스를 지정`한다.

## 토픽 구독하기
컨슈머 생성 후 할 일은 1개 이상의 토픽을 구독하는 것이다. 
subscribe() 메서드는 초픽 목록을 매개 변수로 받기 때문에 매우 간단하다.

정규식을 사용해서 다수의 토픽을 구독하는 것은 카프카와 다른 시스템 사이에 데이터를 복제하는 애플리케이션이나 스트림 처리 애플리케이션에서 매우 흔하게 사용되는 기법

## 롤링 루프
컨슈머 API의 핵심은 서버에 추가 데이터가 들어왔는지 폴링하는 단순한 루트로

폴링 루프는 단순히 데이터를 가져오는 것보다 훨씬 더 많은 일을 하는데, 

 새 컨슈머에서 처음으로 poll()을 호출하면 컨슈머는 GroupCoordinator를 찾아서 컨슈머 그룹에 찹가하고, 파티션을 할당 받는다.


## 오프셋과 커밋
그룹 내의 컨슈머가 어떤 레코드를 읽었는지를 판단할 수 있게 컨슈머가 카프카를 사용해서 각 파티션에서의 위치를 추적할 수 있게 한다.

카프카에서는 파티션에서의 현재 위치를 업데이트 하는 작업을 오프셋 커밋이라고 부른다. 카프카는 레코드를 개별적으로 커밋하지 않고 파티션에서 성공적으로 처리해 낸 마지막 메시지를 커밋함으로써 그 앞의 모든 메시지들 역시 성공적으로 처리됐음을 나타냄.

![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FS3rqU%2FbtqDliReQbh%2FpO3oVfIjscueTTEdBgomok%2Fimg.png)
![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcEh0ir%2FbtqDk7oL2Vy%2FMlF5fk6zJwPdkiOkgPqAS0%2Fimg.png)

### 자동 커밋
오프셋을 커밋하는 가장 쉬운 방법은 컨슈머가 대신하도록 하는 것
설정에 따라 달라지고, 컨슈머의 모든 다른 것들과 마찬가지로 자동 커밋은 폴링 루프에 의해서 실행됨

자동 커밋이 켜진 상태에서 오프셋을 커밋할 때가 되면, 다음 번에 호출된 poll()이 이전 호출에서 리턴된 마지막 오프셋을 커밋함

## 디시얼라이저
카프카 컨슈머는 카프카로부터 받은 바이트 배열을 자바 객체로 변환하기 위해 디시리얼라이저가 필요하다.

AvroDeserializer를 사용하여 스키마 정의로부터 Avro 객체를 생성하는 방법, 카프카에 메시지를 쓸 때 객체를 직렬화하는 방법이 있다

고려할 사항은 이벤트를 쓰기 위해 사용되는 시리얼라이저와 이벤트를 읽어올 때의 디시리얼라이저가 서로 맞아야한다.

-> 이것이 우리가 Avro와 스키마 레지스트리를 사용하는 것이 좋은 이유 중 하나다.

## 독립 실행 컨슈머
경우에 따라 훨씬 더 단순한 것이 필요할 수도 있는데 하나의 컨슈머가 토픽의 모든 파티션으로부터 모든 데이터를 읽어와야 하거나, 토픽의 특정 파티션으로부터 데이터를 읽어와야할 때가 있다.

이럴 때는 그냥 컨슈머에게 특정한 토픽과 파티션을 할당해 주고, 메시지를 읽어서 처리하고, 필요할 경우 오프셋을 커밋하면 됨

리밸런싱 기능을 사용할 수 없고 직접 파티션을 찾아야 한다는 단점을 제외하면 크게 다르지 않다.