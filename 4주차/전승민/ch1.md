# 1. 카프카 시작하기
데이터를 이동시키는 작업에 더 적은 노력을 들일수록 핵심 비즈니스에 집중할 수 있음
파이프라인이 중요한 핵심적인 요소가 되는 이유임
데이터를 어떻게 이동시키느냐의 문제는 데이터 그 자체만큼이나 중요한 것임

## 1.1 발행/구독 메시지 전달
발행/구독 메시지 : 이 패턴의 특징은 전송자(발행자)가 데이터(메시지)를 보낼 때 직접 수신자(구독자)로 보내지 않는 것임
=> 전송자는 어떤 형태로든 메시지를 분류해서 보냄, 수신자는 이렇게 분류된 메시지를 구독함
발행/구독 시스템에는 발행된 메시지를 전달받고 중계해주는 '브로커'가 있음

### 1.1.1 초기의 발행/구독 시스템
발행/구독 패턴은 가운데 간단한 메시지 큐나 프로세스 간 통신 채널을 놓는 것에서 부터 시작함
<img width="747" alt="스크린샷 2024-08-06 오전 12 51 47" src="https://github.com/user-attachments/assets/ab99ff81-aabc-4714-84ac-d0ac0ec7a173">

애플리케이션에서 지표를 대시보드 형태로 보여주는 앱과 연결 후, 지표를 전송함

발행자와 구독자가 직접 연결된 여러 지표 발행자가 있으면 연결을 추적하는 것이 힘들어짐
<img width="662" alt="스크린샷 2024-08-06 오전 12 56 36" src="https://github.com/user-attachments/assets/4bb67874-9e13-449a-b91e-efa3ee1decc5">

이런 문제를 해결할 필요가 있음
=> 모든 애플리케이션으로부터 지표를 받는 하나의 애플리케이션을 두고, 이 지표값들이 필요한 곳에 지표를 질의할 수 있도록 해주는 서버를 제공하면 됨
<img width="749" alt="스크린샷 2024-08-06 오전 12 58 46" src="https://github.com/user-attachments/assets/6d18f1bc-6fb4-43bf-a279-ffef5a828317">

### 1.1.2 개별 메시지 큐 시스템
- 로그 메시지에 대해서도 비슷한 작업을 해줘야 함
<img width="820" alt="스크린샷 2024-08-06 오전 1 03 38" src="https://github.com/user-attachments/assets/60ac0496-1ddb-4862-891b-03285a81398a">

- 비즈니스가 확장함에 따라, 일반화된 유형의 데이터를 발행하고 구독할 수 있는 중앙 집중화된 시스템이 필요함

## 1.2 카프카 입문
- 카프카 : 위에서 제시한 문제들을 해결하기 위한 메시지 발행/구독 시스템
  - => '분산 커밋 로그' or '분산 스트리밍 플랫폼'이라고 불림
- 카프카에 저장된 데이터는 순서를 유지한채로 지속성 있게 보관되며, 결정적으로 읽을 수 있음
- 확장시 성능을 향상시키고 실패가 발생하더라도 데이터 사용에는 문제가 없도록 시스템 안에서 데이터를 분산시켜 저장할 수 있음

### 1.2.1 메시지와 배치
- 카프카에서 데이터의 기본 단위는 '메시지' 임 (데이터베이스의 row나 record와 비슷함)
- 카프카의 입장에서 메시지는 단순히 바이트의 배열일 뿐, 특정한 형식이나 의미가 없음
- 메시지는 key라는 메타데이터를 포함할 수 있음
- 키 역시 카프카 입장에서 별 의미 없는 바이트 배열일 뿐..
- 키는 메시지를 저장할 파티션을 결정하기 위해 사용됨
- 키값에서 일정한 해시값을 생성한 뒤, 이 값을 토픽의 파티션 수로 나눌 때, 나오는 나머지 값에 해당하는 파티션에 메시지를 작성함

- 카프카는 효율성을 위해 배치 단위로 지정함
- 배치 : 같은 토픽의 파티션에 쓰여지는 메시지들의 집합임
- 메시지를 배치 단위로 쓰면, 오버헤드를 줄여주지만, 지연과 처리량 사이에 트레이드오프를 발생시킴
- => 배치가 클 수록 시간당 처리되는 메시지의 수는 늘어나지만, 각각의 메시지가 전달되는 데 걸리는 시간은 늘어남

### 1.2.2 스키마
- 메시지 내용을 이해하기 쉽도록 일정한 구조를 부여하는 것이 권장됨
- 각 애플리케이션의 필요에 따라 사용 가능한 메시지 스키마가 여러 가지 있음 -> 대표적으로 JSON,XML이 있음 (호환성 문제, 타입 문제가 발생...)
- => '아파치 에이브로'를 선호함
- 아파치 에이브로 : 조밀한 직렬화 형식 제공, 스키마가 변경되더라도 코드를 생성할 필요가 없음(메시지 본체와 스키마를 분리하기 때문..)
- 강력한 데이터 타이핑과 스키마 변경에 따른 호환성을 제공함

- 카프카에서는 일관적인 데이터 형식이 중요함 (메시지 쓰기와 읽기 작업을 분리할 수 있도록 해주기 때문..)
- 읽기 작업과 쓰기 작업이 서로 결합되어 있으면, 메시지를 구독하는 애플리케이션들을 구버전과 신버전 형식을
- 동시에 지원하도록 업데이트 해야함
- 이후 메시지를 발행하는 애플리케이션이 신버전 형식을 사용하도록 업데이트 될 수 있을 것임
- 잘 정의된 스키마를 공유 저장소에 저장함으로써 카프카는 두 버전 형식을 동시에 지원하도록 하는 작업 없이도 메시지를 처리함


### 1.2.3 토픽과 파티션
- 카프카에 저장되는 메시지는 토픽 단위로 분류됨 (데이터베이스의 테이블이나 파일시스템의 폴더와 비슷함)
- 토픽은 다시 여러 개의 파티션으로 나누어짐
- 파티션은 하나의 로그에 해당함, 카프카의 중복과 확장성을 제공하는 방법임
  - 각 파티션이 서로 다른 서버에 저장되기에, 하나의 토픽이 수평적 확장을 할 수 있음
  - 파티션은 서로 복제가 가능하기에, 장애 대응에 대응할 수 있음
- 파티션에 메시지가 쓰여질 때는 추가만 가능함(append-only), 읽을 때는 맨 앞부터 순서대로 읽힘
- 토픽에 여러 개의 파티션이 있는 만큼 토픽 안의 메시지 전체에 대해 순서는 보장되지 않음
- 단일 파티션 안에서만 순서가 보장됨
  <img width="691" alt="스크린샷 2024-08-06 오전 11 33 00" src="https://github.com/user-attachments/assets/3715bbe2-0cd0-4c3d-b247-3a873bb29801">

- 스트림 : 하나의 토픽에 저장된 데이터로 간주되며, producer부터 consumer로의 하나의 데이터 흐름을 나타냄

### 1.2.4 프로듀서와 컨슈머
- 카프카 클라이언트는 프로듀서와, 컨슈머 두 종류가 있음
- 이걸 바탕으로 조금 더 고급 클라이언트에는 카프카 커넥트 API 와 스트림 처리에 사용되는 카프카 스트림즈가 있음
- 프로듀서
  - 새로운 메시지를 발행함, 메시지는 특정한 토픽에 쓰여짐
  - 메시지를 쓸 때 토픽에 속한 파티션들 사이에 고르게 분배되어 쓰여짐
  - 특정한 파티션을 지정해서 쓸때도 있음
    - 메시지 key와 key값의 hash를 특정 파티션에 대응시켜주는 방식으로 구현 (동일한 key를 가진 메시지는 같은 파티션에 저장)
  - 커스텀 파티셔너 : 프로듀서가 메시지를 파티션으로 대응시켜주는 다른 규칙을 가진 파티셔너
- 컨슈머
  - 메시지를 읽음, 1개 이상의 토픽을 구독해서, 컨슈머에 저장되는 메시지들을 각 파티션에 쓰여지는 순서대로 읽음
  - 메시지의 offset(지속적으로 증가하는 정수값,메타데이터..)을 기록해, 어느 메시지까지 읽었는지를 유지함
  - offset은 반드시 단조증가할 필요는 없음
  - 파티션별로 다음 번에 사용가능한 오프셋 값을 저장함
- 컨슈머 그룹
  - 토픽에 저장된 데이터를 읽어오기 위해 협업하는 하나 이상의 컨슈머로 구성됨
  - 컨슈머 그룹은 각 파티션이 하나의 컨슈머에 의해서만 읽히도록 함
  - 컨슈머에서 파티션으로의 대응 관계는 파티션 소유권이라고 부름
    - 이 방법으로 대량의 메시지를 갖는 토픽들을 읽기 위해 컨슈머들은 슈평 확장할 수 있음
    - 컨슈머에 장애가 발생하더라도, 그룹 안의 다른 컨슈머들이 장애가 발생한 컨슈머의 역할을 대체함
<img width="662" alt="스크린샷 2024-08-06 오전 11 57 31" src="https://github.com/user-attachments/assets/aa08b1f0-d74a-4b88-84f2-25e5c7598aea">


### 1.2.5 브로커와 클러스터
- 브로커 : 하나의 카프카 서버를 말함
- 브로커는 프로듀서로부터 메시지를 전달받아 오프셋을 할당한 뒤, 디스크 저장소에 작성함
- 브로커는 컨슈머의 파티션 읽기 또한 처리하고, 발행된 메시지를 보내줌
- 시스템 마다 다르지만 초당 수천개~수백만 개의 메시지를 쉽게 처리함

- 브로커는 클러스터의 일부로서 작동하도록 설계됨
- 하나의 클러스터 안에 여러개의 브로커가 포함될 수 있음, 그중 하나의 브로커가 클러스터 컨트롤러의 역할을 함
  - 컨트롤러 : 파티션을 브로커에게 할당하거나, 장애가 발생한 브로커를 모니터링함 (관리 기능)
- 파티션 리더 : 파티션은 클러스터 안의 브로커 중 하나가 담당하는데, 이 브로커를 파티션 리더라고 부름
- 복제된 파티션이 여러 브로커에게 할당되는데, 이것들을 '팔로워'라고 부름
- 복제 기능은 파티션의 메시지를 중복 저장함으로써, 리더 브로커에게 장애가 발생할때, 팔로워중 하나가 리더 역할을 수행함
- 모든 프로듀서는 리더 브로커에게 메시지를 발행해야하지만, 컨슈머는 리더나 팔로워 중 하나로부터 데이터를 읽어올 수 있음
<img width="369" alt="스크린샷 2024-08-06 오후 11 08 39" src="https://github.com/user-attachments/assets/30169dce-509a-4da0-a26f-7268e7d08bee">


- 카프카의 핵심 기능 중에 보존 기능이 있음
  - 카프카 브로커는 토픽에 대해 기본적인 보존 설정이 되어 있음
  - 특정 기간동안 보존하거나, 파티션의 크기가 사이즈에 도달할때까지 데이터를 보존함
### 1.2.6 다중 클러스터
- 카프카가 확장되어감에 따라 다수의 클러스터를 운용하는 것이 더 나은 경우가 있음
  - 데이터 유형별 분리
  - 보안 요구사항을 충족시키기 위한 격리
  - 재해 복구를 대비한 다중 데이터 센터
  - 카프카를 다수의 데이터 센터에서 운용할때는, 데이터센터간 메시지를 복제해줄 필요가 있음
    - 카프카 클러스터의 복제 메커니즘은 다중 클러스터 사이에서가 아닌 하나의클러스터 안에서만 작동하도록 설계되었음
- 미러메이커 : 데이터를 다른 클러스터(다른 데이터센터)로 복제하는 데 사용되는 툴
  - 큐로 연결된 카프카 컨슈머와 프로듀서에 불과함
<img width="338" alt="스크린샷 2024-08-06 오후 11 08 45" src="https://github.com/user-attachments/assets/cce8b78a-46f2-46ec-8874-debc08eb7091">

## 1.3 왜 카프카인가?
1. 다중 프로듀서 : 카프카는 여러 프로듀서를 처리할 수 있음
2. 다중 컨슈머 : 많은 컨슈머가 서로 간섭 없이 메시지 스트림을 읽을 수 있음
3. 디스크 기반 보존 : 메시지를 지속성 있게 저장할 수 있음(컨슈머들이 항상 실시간으로 데이터를 읽을 필요는 없음, 유실 없이 데이터를 처리함)
4. 확장성 : 확장성이 좋기에, 어떠한 크기의 데이터도 쉽게 처리할 수 있음 (시스템 전체의 가용성에 영향을 주지 않으면서 확장이 가능함)
5. 고성능
6. 플랫폼 기능
7. 데이터 생태계

### 이용 사례
1. 활동추적
2. 메시지 교환 : 메시지를 포매팅 or 데코레이팅, 여러 메시지를 취합해 하나의 메시지로 전달, 사용자가 원하는 메시지를 모아서 수신 방식을 적용함
3. 지표 및 로그 수집
4. 커밋 로그 : 카프카는 데이터베이스의 커밋 로그 개념을 기반으로 만들어짐
5. 스트림 처리 : 실시간 데이터 처리를 함


사진 자료 출처) - 감사합니다 :)
https://wngus606.tistory.com/entry/Kafka-The-Definitive-Guide-Chapter-1-%EC%B9%B4%ED%94%84%EC%B9%B4-%ED%9B%91%EC%96%B4%EB%B3%B4%EA%B8%B0-1
https://soft.plusblog.co.kr/29
