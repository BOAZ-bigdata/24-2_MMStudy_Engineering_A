# 카프카 프로듀서: 카프카에 메시지 쓰기
- 카프카를 사용하기 위해서는 애플리케이션을 생성해야함
- 애플리케이션이 카프카에 메시지를 써야 하는 상황에는 여러 가지가 있음
  - 사용자 행동 기록, 성능 메트릭 기록, 로그 메시지 저장, 스마트 가전에서의 정보 수집
  - 다른 애플리케이션과의 비동기적 통신 수행, 임의의 정보를 DB에 저장하기 전 버퍼링 등..
- 요구 조건에 따라 카프카 메시지 쓰기 위한 프로듀서 API 사용하는 방식과 설정에 영향을 미침
<img width="754" alt="스크린샷 2024-08-07 오전 12 41 26" src="https://github.com/user-attachments/assets/3897ac11-9ea1-4d98-b6e2-d8f2622be82f">

- 카프카 메시지 쓰는 작업은 ProducerRecord 객체를 생성함으로써 시작함
- ProducerRecord를 전송하는 API를 호출했을 때 프로듀서가 가장 먼저 하는 일은 키,값 을 직려로하해서 바이트 배열로 변환 후 네트워크 상 전송하게 함
- ProducerRecord 객체의 키의 값에 따라 파티션을 결정하는 역할을 함
- 메시지가 전송될 토픽과 파티션이 확정되면 프로듀서는 이 레코드를
- 같은 토픽 파티션으로 전송될 레코드들을 모은 레코드 배치에 추가함
- 별도의 스레드가 이 레코드 배치를 적절한 카프카 브로커에게 전송함
- 브로커가 메시지를 받으면 응답이 돌아옴
  - 성공하면 Recordmetadata 객체를 리턴함
  - 실패할경우 error 리턴 -> 재전송 시도함...

## 카프카 프로듀서 생성하기
- 원하는 속성 지정해서 프로듀서 객체를 생성해야함
### 프로듀서는 3개의 필수 속성값을 가짐
  - bootstrap.servers
    - 카프카 클러스터와 첫 연결 위해 사용
    - 프로듀서가 사용할 브로커의 host:port 목록임
    - 최소 2개 이상을 지정할 것을 권장
  - key.serializer -> key.serializer
    - 카프카에 쓸 레코드의 '키' 값을 직렬화하기 위해 사용하는 serializer 클래스 이름임
  - value.serializer -> value.serializer
    - 카프카에 쓸 레코드의 '밸류값'을 직렬화하기 위해 사용하는 serializer 클래스 이름임
1. Properties 객체 생성
2. StringSerializer를 사용하면됨
3. Properties 객체를 넘겨서, 새로운 프로듀서를 생성하면됨

### 매시지 전송방법
  1. 파이어 앤 포겟 : 메시지를 서버에 전송만 하고 결과는 신경x
  2. 동기적 전송 : 카프카 프로듀서는 언제나 비동기적으로 작동하지만, 다음 메시지를 보내기위해서는 get()을 통해서 실제 작업 성공 여부 확인해야됨
     - KafkaProducer에는 두 종류의 에러가 있음
       1. 재시도 가능한 에러 : 재전송을 통해 해결, 연결 에러, 전송받은 브로커가 파티션의 리더가 아닌 문제..
       2. 재시도 불가능한 에러 : 메시지 크기가 너무 클때..
  4. 비동기적 전송 : call back함수와 send()를 호출하면, 브로커로부터 응답 받을때 자동으로 콜백 함수가 호출됨
     - 메시지를 비동기적으로 전송하고도 여전히 에러를 처리하는 경우를 위해
     - 프로듀서는 레코드를 전송할 때 콜백을 지정하도록 함

### 프로듀서 설정하기
  - 프로듀서는 많은 수의 설정값을 가짐
  - client.id
    - 브로커가 프로듀서가 보낸 메시지를 서로 구분하기 위해 사용하는 값
    - 로그 메시지 출력, 성능 메트릭 값 집계할때, 클라이언트별로 사용량을 할당할 때 사용함
    - 문제가 발생했을때 트러블슈팅을 쉽게 함
  - acks
    - 프로듀서가 쓰기 작업이 성공했다고 판별하기 위해 얼마나 많은 파티션 레플리카가 해당 레코드를 받아야하는지 결정함
    - 기본값은 리더가 해당 레코드 받은 뒤, 쓰기 작업이 성공했다고 응답하는 것
      - acks = 0 : 프로듀서는 전달이 성공으로 간주하고, 브로커 응답을 안기다림 -> 유실 발생할 수 있지만, 높은 처리량에 유리함
      - acks = 1 : 프로듀서는 리더 래플리카가 메시지 받는 순간 브로커에게 성공 응답을 받음, 유실을 피하기 위해 재전송하지만, 리더 크러시(리더x)때는 에러가 발생함
      - acks = all : 프로듀서는 메시지가 모든 인-싱크 래플리카에 전달된 뒤 브로커에게 성공 응답을 받음 (최소 2개 이상의 브로커가 해당 메시지를 가져야함)

### 메시지 전달 시간
- send()를 호출했을 때, 성공 or 실패까지 얼마나 시간이 걸리는지가 중요함
- ProducerRecord를 보낼 때 걸리는 시간을 두 구간으로 나누어 처리함
  - send()에 대한 비동기 호출이 이뤄진 시각부터 ~ 결과를 리턴할때까지 걸리는 시간
  - 성공적으로 리턴한 시각부터(성공,실패 상관없이) ~ 콜백이 호출될때까지 걸리는 시간
<img width="848" alt="스크린샷 2024-08-07 오전 1 36 52" src="https://github.com/user-attachments/assets/2c722174-61dd-4bd9-a6e2-360868f63aa3">

- 위 그림은 프로듀서 내부의 데이터 흐름과, 매개변수들이 어떻게 상호작용하는지 보여줌
매겨변수 설명은 책 p.60 ~p.65 참고하기

### 시리얼라이저
- 프로듀서를 설정할 때는 반드시 시리얼라이저를 지정해야 함(데이터 직렬화를 위해)
- 모든 데이터를 직렬화 할 수 없기에, 일반적인 레코드를 직렬화할 수 있어야 함
- 커스텀 시리얼라이저
  - 카프카로 전송할 객체가 문자열이나 정숫값이 아닐때는, 두 가지 선택지가 있음
    1. 레코드 생성을 위해 범용 직렬화 라이브러리 사용 (이걸 더 권장) - 아파치 에이브로를 사용한 직렬화.. 책에서 코드 살펴보기
    2. 사용하고 있는 객체를 직렬화하기 위해 커스텀 직렬화 로직을 작성함
   
### 파티션
- ProducerRecord 객체는 토픽,키,밸류 값을 포함함
- 키의 역할은 두가지임
  - 그 자체로 메시지에 저장
  - 하나의 토픽에 속한 여러 개 파티션 중 해당 메시지가 저장될 파티션을 결정짓는 기준점 (같은 키는 같은 파티션에 저장됨)
  - 키값이 null인 경우, 사용가능한 토픽의 파티션 중 하나에 랜덤하게 저장됨 (균형을 위해 라운드 로빈 알고리즘 사용)- 접착성 처리 이용(p.74 추가 설명)
  - 키값이 지정된 경우이면, 해시한 결과를 기준으로, 파티션을 특정함
  - 랜덤 파티션 할당과 접착성 랜덤 파티션 할당을 수행하기도 함

- 커스텀 파티셔너
  - 기본 파티셔너를 사용하면 특정 파티셔너에 집중되는 경우가 발생할 수 있음
  - 특정 파티셔너를 커스텀해서 컨트롤 할 필요가 있음
### 인터셉터
- 카프카 클라이언트의 코드를 건들지 않고, 작동을 변경할때가 있음
- 회사 내에서 사용하는 모든 애플리케이션에 동일한 작동을 집어 넣거나, 원래 코드를 사용할 수 없는 상황 등...
- 이때 카프카의 ProducerInterceptor를 사용함
p.77 메소드 확인하기
  
### 쿼터,스로틀링
- 카프카 브로커에게 쓰기/읽기 속도를 제한할 수 있는 기능이 있음
- 3가지 쿼터 타입에 대한 한도를 설정할 수 있음
  1. 쓰기 쿼터 : 클라이언트가 전송하거나 받는 속도를 초당 바이트 수 단위로 제한함
  2. 읽기 쿼터 : 쓰기 쿼터와 동일
  3. 요청 쿼터 : 브로커가 요청을 처리하는 시간 비율 단위로 제한함
