# 9장 데이터 파이프라인 구축하기
데이터 파이프라인에 카프카를 통합해 넣는 작업이 쉽지 않은 작업이라는 것을 알아차려서 조직마다 카프카를 사용해서 쉽게 작업할 수 있게 API를 추가하기로 했다.

데이터 파이프라인에 있어서 카프카가 갖는 주요한 역할은 `데이터 파이프라인의 다양한 단계 사이사이에 있어 매우 크고 안정적인 버퍼 역할을 해준다는 것`!

-> 실질적으로 `데이터 파이프라인의 데이터를 쓰는 쪽과 읽는 쪽을 분리할 수 있다는 점`은 신뢰성, 보안성, 효율성과 함께 카프카가 대부분의 데이터 파이프라인에 적합한 이유다!

## 데이터 파이프라인 구축 시 고려사항

1) 적시성 : 데이터 읽기/쓰기를 시간적 민감도에 맞춰 조절 가능.

2) 신뢰성 : 데이터 손실과 중복 없이 전달.

3) 높으면서도 조정 가능한 처리율 : 분산 시스템으로 높은 데이터 처리율 지원.

4) 데이터 형식 : 다양한 데이터 형식 지원.

5) 변환 : ETL은 데이터 파이프라인이 통과하는 데이터에 변경을 가하는 작업까지도 담당. ELT는 데이터 파이프라인에 대상 시스템에 전달되는 데이터가 원본 데이터와 최대한 비슷하도록 최소한의 변환만을 수행한다.

    - 카프카 커넥트는 원본 시스템의 데이터를 카프카로 옮길 때 혹은 카프카의 데이터를 대상 시스템으로 옮길 때 단일 레코드를 변환할 수 있게 해주는 단일 메시지 변환 기능을 탑재하고 있다.

        -> 데이터의 변환: 원본 시스템에서 데이터를 가져오거나 카프카에서 데이터를 대상으로 보내기 전에, 각 개별 메시지를 특정 방식으로 변환할 수 있다는 의미

        -> 즉, ETL의 방식과 더 가깝다. 

6) 보안 : 데이터 암호화를 지원

7) 장애처리 : 에러 복구

8) 결합과 민첩성 : 데이터 원본과 대상을 분리할 수 있게끔

## 카프카 커넥트 VS 프로듀서/컨슈머
카프카에 데이터를 쓰거나 읽을 때 방법 
1) 전통적인 프로듀서와 컨슈머 사용하는 방법 
2) 커넥트 API와 커넥터를 사용하는 방법
- 카프카를 직접 코드나 API 작성하지 않고, 변경도 할 수 없는 데이터 저장소에 연결시켜야 할 때 사용. 
- 카프카 커넥트를 사용하려면 데이터 저장소에 맞는 커넥터를 이용하면 됨

## 카프카 커넥트
카프카 커넥트는 카프카와 다른 데이터 저장소 사이에 확장성과 신뢰성을 가지면서 데이터를 주고받을 수 있는 수단 제공

카프카 커넥터는 데이터를 이동시키는 커넥터 플러그인을 사용하여 대용량 데이터 이동을 병렬 처리.

- 커넥트는 여러 워커 프로세스들의 클러스터 형태로 실행됨


- 소스 커넥터 역할: 외부 시스템(데이터베이스, API 등)에서 데이터를 추출하여 카프카의 특정 토픽으로 보냄
- 싱크 커넥터 역할: 카프카의 특정 토픽에서 데이터를 가져와 외부 시스템으로 전송함.

### 커넥터와 태스크
커넥터가 수행하는 작업

1. 커넥터에서 몇 개의 태스크가 실행되어야 하는지 결정한다
2. 데이터 복사 작업을 각 태스크에 어떻게 분할해 줄지 결정한다
3. 워커로부터 태스크 설정을 얻어와서 태스크에 전달해준다

커넥터는 얼마나 많은 태스크가 필요한지 결정하고 실행시킬 태스크의 수를 결정시킨다. 

#### 태스크
태스크는 데이터를 실제로 카프카에 넣거나 가져오는 작업을 담당. 모든 태스크는 워커로부터 컨텍스트를 받아서 초기화됨.

소스 태스크: 소스 커넥터가 생성하는 태스크로 외부 시스템을 폴링해서 워커가 카프카 브로커로 보낼 레코드 리스트를 리턴

싱크 태스크: 싱크 커넥터가 생성하는 태스크로 워커를 통해 카프카 레코드를 받아서 외부 시스템에 쓰는 작업 담당

### 워커
워커는 커넥터 태스크와 서로 다른 책임을 맡는 다는 것을 이해해야 함. 
커넥터와 태스크는 데이터 통합에서 데이터 이동 단계를 맡은 것이고, 워커는 REST API, 설정 관리, 신뢰성, 고가용성, 규모 확장성 부하 분산을 담당

-> 이렇게 분리되는 것이 고전적인 컨슈머/프로듀서 API가 아닌 커넥트 API를 사용할 때의 주된 이점 

-> 커넥터의 형태로 데이터 복사를 구현한 뒤 워커 프로세스에 커넥터를 꽂아 넣기만 하면 복잡한 운영상의 이슈는 워커가 해결해준다!

### 컨버터 및 커넥트 데이터 모델
소스 커넥터는 데이터 API를 사용해서 데이터 객체를 생성하는 방법을 알고 있지만 커넥트 워커가 이 객체들을 카프카에 어떻게 써야하는지에 대한 의문이 생김

-> 이때 컨버트를 사용해서 커넥트 API는 커넥터 구현과 무관하게 카프카에 서로 다른 형식의 데이터를 저장할 수 있도록 한다.

-----

# 10장 클러스터간 데이터 미러링하기
상호 의존하는 클러스터 사이에 데이터를 지속적으로 복사해줘야하는 경우, 카프카 클러스터 간의 데이터 복제를 `미러링`이라고 부른다.
아파치 카프카에는 클러스터간 데이터 복제를 수행하기 위한 툴로 `미러메이커`를 포함하고 있다. 

### 클러스터가 미러링 활용 사례
- 지역 및 중앙 클러스터
- 고가용성과 재해 복구
- 규제
- 클라우드 마이그레이션
- 엣지 클러스터로부터의 데이터 집적

## 다중 클러스터 아키텍처
데이터 센터 간 통신에서 현실적으로 고려해야 할 사항들을 볼텐데 이때 특정한 네트워크 환경에서의 트레이드오프를 반영한다는 것을 이해하는 것이 좋다!

### 허브-앤-스포크 아키텍처
여러 개의 로컬 카프카 클러스터와 한 개의 중앙 카프카 클러스터가 있는 상황을 상정한 것

- 데이터가 여러 개의 데이터센터에서 생성되고, 일부 컨슈머는 전체 데이터를 사용해야 할 경우 사용됨
- 로컬 데이터센터에서 데이터가 생성되고, 각각의 데이터센터에 저장된 이벤트가 중앙 데이터센터로 단 한 번만 미러링된다는 점.

- 하지만 지역 데이터센터에 있는 애플리케이션은 다른 데이터센터에 있는 데이터를 사용할 수 없다.(중앙으로만 연결되니까)

### 액티브-액티브 아키텍처
2개 이상의 데이터센터가 전체 데이터의 일부 혹은 전체를 공유하면서 각 데이터센터가 모두 읽기와 쓰기를 수행할 수 있는 경우

- 은근 데이터센터에서 사용자들의 요청을 처리할 수 있다
- 데이터를 여러 위치에서 비동기적으로 읽거나 변경할 경우 발생하는 충돌을 피하기 어려움
- 각 쌍의 데이터센터의 양 방향에 대해 미러링 작업이 필요
- 같은 데이터가 클러스터 사이를 오가면서 끝없이 순환 미러링되는 것을 막아야 함

- 글로벌 서비스 제공이나 서비스 중단이 용납될 수 없는 환경에서 매우 효과적이라고 함. 

### 액티브-스탠바이 아키텍처
재해 대비를 위해서 구현하는. 하나의 데이터센터 안에 두 개의 클러스터를 가지고 있다고 하면 첫 번째 클러스터의 거의 모든 데이터를 가지고 있다가 이게 망가지면 두 번째 클러스터가 필요할 수 있음

두 번째 클러스터를 설치한 뒤에 첫 번째 클러스터의 모든 이벤트를 미러링하는 프로세스를 설치하면 됨.

DR(diaster recovery) 클러스터로 장애 복구를 어떻게 하는 걸까?
1. 복구 시간 목표를 설정해야하고
2. DR 클러스터가 주 클러스터에서 얼마나 뒤처져 있는지 항상 모니터링해야 하지만, 뒤처져 있더라도 예쌍치 못한 장애 복구는 어느 정도의 유실을 감수해야한다.
3. 다른 클러스터로 옮겨간 애플리케이션이 데이터를 읽어오기 시작해야하는 위치(=시작 오프셋)을 정해야한다.
- 자동 오프셋 재설정
    - 아파치 카프카 컨슈머는 사전에 커밋된 오프셋이 없을 경우 파티션의 맨 앞에서부터 읽을지 맨 뒤에서부터 읽을지 결정하는 오프셋을 가진다.
- 오프셋 토픽 복제
    - 컨슈머가 자신의 오프셋을 특별한 토픽에 커밋하고 이 토픽을 DR 클러스터로 미러링해줘서 여기서 읽기 작업을 시작하는 컨슈머가 이전에 주 클러스터에 마지막으로 커밋한 오프셋부터 작업을 재개
- 시간 기반 장애 복구
    - 애플리케이션에 시작 시간을 지정할 수 있는 사용자의 설명 넣는 방법
- 오프셋 변환
    - 오프셋 매핑은 클러스터 간의 오프셋 값 차이가 달라질 때 저장되는데 주 클러스터 오프셋에 매핑되는 DR 클러스터 오프셋을 찾아서 여기부터 작업하게 하는 방법
4. 장애 복구 후 주 클러스터를 다시 DR 클러스터로 역할을 변경해주기

## 아파치 카프카의 미러메이커
미러메이커는 두 데이터센터 간의 데이터 미러링을 위해 사용되는 툴로 현재는 재해복구, 백업, 마이그레이션, 데이터 집적 등 넓은 범위의 활용 사례를 지원할 수 있도록 복잡한 토폴리지(네트워크의 요소들을 물리적으로 연결해놓은 것)를 쉽게 설정할 수 있다.

미러메이커에서는 각각의 태스크가 한 쌍의 컨슈머와 프로듀서로 이뤄진다.

### 액티브-스탠바이 복제 흐름을 정의하기 위한 미러메이커 설정 예제
- 복제 흐름 설정
- 미러링 토픽
-  컨슈머 오프셋 마이그레이션
- 토픽 설정 및 ACL 마이그레이션
- 커넥터 태스크

- 설정 접두어

### 미러메이커 배포

미러 메이커는 카프카 커넥트에서 미러메이커를 실행시킬 수도 있고, 별도로 설치된 분산 모드 카프카 커넥트 클러스터에서 커넥터 형태로 실행될 수도 있다.

지역 읽기 - 원격 쓰기를 해야할 경우
- 데이터 간에 전송될 때는 암호화를 해야하지만, 데이터센터 안에서는 암호화할 필요가 없는 데이터
- 하이브리드 환경
    - 온프레미스 클러스터의 토픽을 클라우드 클러스터로 미러링 하는 것


# 11장 보안 
보안은 가장 강력하고 또 최신인 기능을 사용하는 것이 언제나 선호되지만 보안을 향상시키려면 많은 비용이 드니까 어느 정도의 절충이 필요하다

## 보안 설정 적용하기
- 인증: 사용자가 누구인지 식별한다
- 인가: 사용자가 무엇을 할 수 있는지 결정
- 암호화: 누설과 위조로부터 데이터 보호
- 감사: 사용자가 무엇을 했는지 추적
- 쿼터: 자원을 얼마나 많이 사용할 수 있는 지 조절

## 보안 프로토콜
카프카 브로커에 1개 이상의 엔드포인트를 가진 리스너 설정이 있는데, 클라이언트로부터의 연결을 받는 것이 바로 이 리스너다.
각각의 리스너는 각자의 보안 설정을 가질 수 있다

#### TLS: 이전 버전의 이름인 SSL로도 불리고, 서버와 클라이언트 사이의 인증 뿐만 아니라 암호화도 지원

-> 사설 네트워크 안에서 인증이나 암호화가 필요없을 정도로 민감하지 않은 데이터를 처리할 때만 적합

-> 인터넷에서 가장 많이 사용되는 암호화 프로토콜 중 하나

#### SASL: 연결 지향 프로토콜에서 서로 다른 메커니즘을 사용한 인증을 지원하는 프레임워크

각 카프카 보안 프로토콜은 전송 계층(PAINTEXT, SSL)과 인증 계층(SSL, SASL)을 조합해서 정외됨

#### SASAL_PLAINTEXT: 암호화는 진행하지 않기 때문에 사설 네트워크 안에서만 적합

#### SASL_SSL: 암호화 뿐만 아니라 클라이언트/서버 인증도 지원되기 때문에 안전하지 않은 네트워크에서 적합

## 인증
서버와 클라이언트의 사이에서 서로의 신원을 확인하는 과정

-> 카프카 브로커와 클라이언트 간의 통신이 시작될 떄 신원을 파악하는 과정

`SSL/TLS:` 클라이언트와 브로커 간의 안전한 통신을 보장한다. 이를 통해 메시지가 중간에서 탈취되는 것을 방지하며, 양쪽이 서로의 신원을 확인하는 데 사용된다.

`SASL/PLAIN`: 사용자 이름과 비밀번호를 사용한 간단한 인증 방법

`SASL/SCRAM`: 비밀번호 기반 인증을 강화함

`ASL/GSSAPI `(Kerberos): 케르베로스를 사용하는 강력한 인증 방식으로, 대규모 엔터프라이즈 환경에서 자주 사용됨. Kerberos는 중앙화된 인증 서버를 통해 사용자를 인증하고, 인증된 사용자에게 티켓을 발급하여 통신을 보호함

## 인가
인가는 사용자가 자원에 대해 어떠한 작동을 수행할 수 있는지를 결정하는 절차
인증된 클라이언트가 특정 작업을 수행할 수 있는 권한을 관리

카프카 브로커는 ACL을 사용해서 인가를 관리함.

ACL은 사용자가 특정 리소스(토픽, 컨슈머 그룹 등)에 대해 허용된 작업(읽기, 쓰기, 삭제 등)을 정의하는 규칙

관리자는 주어진 사용자 또는 애플리케이션이 Kafka 클러스터 내에서 수행할 수 있는 작업을 세부적으로 제어할 수 있다.

카프카 기본 인가 전략: : 카프카에서는 기본적으로 DENY가 우선 적용된다.

즉, 특정 리소스에 대해 명시적으로 허가되지 않으면 기본적으로 접근이 
거부된다는 뜻.