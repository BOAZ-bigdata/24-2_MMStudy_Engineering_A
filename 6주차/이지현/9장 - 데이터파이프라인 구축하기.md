# 9장 데이터 파이프라인 구축하기
데이터 파이프라인에 카프카를 통합해 넣는 작업이 쉽지 않은 작업이라는 것을 알아차려서 조직마다 카프카를 사용해서 쉽게 작업할 수 있게 API를 추가하기로 했다.

데이터 파이프라인에 있어서 카프카가 갖는 주요한 역할은 `데이터 파이프라인의 다양한 단계 사이사이에 있어 매우 크고 안정적인 버퍼 역할을 해준다는 것`!

-> 실질적으로 `데이터 파이프라인의 데이터를 쓰는 쪽과 읽는 쪽을 분리할 수 있다는 점`은 신뢰성, 보안성, 효율성과 함께 카프카가 대부분의 데이터 파이프라인에 적합한 이유다!

## 데이터 파이프라인 구축 시 고려사항

1) 적시성 : 카프카를 쓰는 쪽과 읽는 쪽 사이의 시간적 민감도에 대한 요구 조건을 분리시키는 거대한 버퍼로 생각하여 시스템마다 다른 적시성 요구 족건을 지원하는 것

2) 신뢰성 : 원본 시스템에서 발생한 모든 이벤트가 유실도, 중복도 없이 목적지에 도착해야하는 것

3) 높으면서도 조정 가능한 처리율 : 카프카는 높은 처리율을 받아낼 수 있는 분산시스템이기 때문에 처리율에 관한 요구 조건이 상향되는 와중에도 동작 가능하게 하는 것

4) 데이터 형식 : 카프카 자체와 커넥트 API는 데이터 형식에 독립적이라서 카프카에 사용하는 데이터 형식이 무엇이든 간에 사용할 수 있는 커넥터는 영향을 받지 않는다.

5) 변환 : ETL은 데이터 파이프라인이 통과하는 데이터에 변경을 가하는 작업까지도 담당. ELT는 데이터 파이프라인에 대상 시스템에 전달되는 데이터가 원본 데이터와 최대한 비슷하도록 최소한의 변환만을 수행한다.

    - 카프카 커넥트는 원본 시스템의 데이터를 카프카로 옮길 때 혹은 카프카의 데이터를 대상 시스템으로 옮길 때 단일 레코드를 변환할 수 있게 해주는 단일 메시지 변환 기능을 탑재하고 있다.

        -> 데이터의 변환: 원본 시스템에서 데이터를 가져오거나 카프카에서 데이터를 대상으로 보내기 전에, 각 개별 메시지를 특정 방식으로 변환할 수 있다는 의미

        -> 즉, ETL의 방식과 더 가깝다. 

6) 보안 : 데이터 암호화를 지원

7) 장애처리 : 에러 복구

8) 결합과 민첩성 : 데이터 원본과 대상을 분리할 수 있게끔

## 카프카 커넥트 VS 프로듀서/컨슈머
카프카에 데이터를 쓰거나 읽을 때 방법 
1) 전통적인 프로듀서와 컨슈머 사용하는 방법 
2) 커넥트 API와 커넥터를 사용하는 방법
- 카프카를 직접 코드나 API 작성하지 않고, 변경도 할 수 없는 데이터 저장소에 연결시켜야 할 때 사용. 
- 카프카 커넥트를 사용하려면 데이터 저장소에 맞는 커넥터를 이용하면 됨

## 카프카 커넥트
카프카 커넥트는 카프카와 다른 데이터 저장소 사이에 확장성과 신뢰성을 가지면서 데이터를 주고받을 수 있는 수단 제공

- 커넥트는 커넥터 플러그인을 개발하고 실행하기 위한 API와 런타임 제공, 커넥터 플러그인은 데이터를 이동시키는 것을 담당
- 커넥트는 여러 워커 프로세스들의 클러스터 형태로 실행됨
- 커넥터는 대용량의 데이터 이동을 병렬화하여 처리하고 워커의 유휴 자원을 더 효율적으로 활용하기 위해 태스크를 추가로 실행시킴

- 소스 커넥터 역할: 외부 시스템(데이터베이스, API 등)에서 데이터를 추출하여 카프카의 특정 토픽으로 보냄
- 싱크 커넥터 역할: 카프카의 특정 토픽에서 데이터를 가져와 외부 시스템으로 전송함.

### 커넥터와 태스크
커넥터가 수행하는 작업

1. 커넥터에서 몇 개의 태스크가 실행되어야 하는지 결정한다
2. 데이터 복사 작업을 각 태스크에 어떻게 분할해 줄지 결정한다
3. 워커로부터 태스크 설정을 얻어와서 태스크에 전달해준다

커넥터는 얼마나 많은 태스크가 필요한지 결정하고 실행시킬 태스크의 수를 결정시킨다. 

#### 태스크
태스크는 데이터를 실제로 카프카에 넣거나 가져오는 작업을 담당. 모든 태스크는 워커로부터 컨텍스트를 받아서 초기화됨.

소스 태스크: 소스 커넥터가 생성하는 태스크로 외부 시스템을 폴링해서 워커가 카프카 브로커로 보낼 레코드 리스트를 리턴

싱크 태스크: 싱크 커넥터가 생성하는 태스크로 워커를 통해 카프카 레코드를 받아서 외부 시스템에 쓰는 작업 담당

### 워커
워커는 커넥터 태스콰 서로 다른 책임을 맡는 다는 것을 이해하자. 커넥터와 태스크는 데이터 통합에서 데이터 이동 단계를 맡은 것이고, 워커는 REST API, 설정 관리, 신뢰성, 고가용성, 규모 확장성 부하 분산을 담당

-> 이렇게 분리되는 것이 고전적인 컨슈머/프로듀서 API가 아닌 커넥트 API를 사용할 때의 주된 이점 

-> 커넥터의 형태로 데이터 복사를 구현한 뒤 워커 프로세스에 커넥터를 꽂아 넣기만 하면 복잡한 운영상의 이슈는 워커가 해결해준다!

### 컨버터 및 커넥트 데이터 모델
소스 커넥터는 원본 시스템의 이벤트를 읽어와서 스키마, 밸류 순서쌍을 생성하고, 싱크 커넥터는 이 반대의 작업을 수행하는데, 소스 커넥터는 데이터 API를 사용해서 데이터 객체를 생성하는 방법을 알고 있지만 커넥트 워커가 이 객체들을 카프카에 어떻게 써야하는지에 대한 의문이 생김

-> 이때 사용되는 것이 컨버터! 사용자가 워커나 커넥터를 설정할 때, 카프카에 데이터를 저장할 때 사용하고자 하는 컨버터를 선택해준다. 

-> 컨버트를 사용해서 커넥트 API는 커넥터 구현과 무관하게 카프카에 서로 다른 형식의 데이터를 저장할 수 있도록 한다.