# 데이터 파이프라인 구축
- 기업이나 조직에서 필요로 하는 데이터 파이프라인에 카프카를 통합해 넣는 작업은 쉽지 않음
- 밑바닥부터 개발하는게 아닌, API를 추가함
- 카프카는 데이터 파이프라인 사이에서 매우 크고 안정적인 버퍼 역할을 해줌
  - 데이터 파이프라인의 쓰는 쪽과 읽는 쪽을 분리하였기 때문
  - 원본에서 오는 동일한 데이터를 서로 다른 적시성과 가용성을 요구하는 애플리케이션이나 시스템에 보낼 수 있음
## 파이프라인 구축 시 고려사항
### 적시성
- 좋은 데이터 통합 시스템은 각각의 데이터 파이프라인에 대해 서로 다른 적시성 요구 조건을 지원하면서도, 업무에 대한 요구 조건이 변경되었을때도 이전이 쉬워야함
- 카프카는 쓰는 쪽과 읽는 쪽 사이의 시간적 민감도에 대한 요구 조건을 분리시키는 거대한 버퍼로 생각하면됨
- ex) 쓰는 쪽 : 실시간으로 쓰지만, 읽는 쪽 : 배치처리로 읽어올 수 있음
- 백프레셔 적용 역시 단순하게 해줌
  - 데이터 소비 속도가 온전히 읽는 쪽에 의해 결정되기 때문
  - cf)
  - 백프레셔는 소비자가 생산자의 메시지를 처리하는 속도를 따라가지 못할 때 발생하는 문제를 의미
### 신뢰성
- 신뢰성을 고려할때 전달 보장 역시 고려해야 함
- 데이터 유실을 허용하는 시스템도 있지만, 대부분은 최소 한번 보장을 요구함
- 원본 시스템에서 발생한 이벤트가 모두 목적지에 도착해야함
- 모든 이벤트가 유실,중복 없이 모두 목적지에 도착해야함
### 높으면서도 조정 가능한 처리율
- 매우 높은 처리율을 가질 수 있도록 확장이 가능해야 함
- 쓰는 쪽과 읽는 쪽이 분리되어 있기 때문에, 프로듀서의 처리율과 컨슈머의 처리율을 묶어서 생각 안해도 됨
- 카프카는 독립적으로 프로듀서나 컨슈머를 추가해 확장함
### 데이터 형식
- 서로 다른 데이터 형식과 자료형을 적절히 사용해야 함
- 카프카 자체와 커넥트 API는 데이터 형식에 완전히 독립적임
  - 카프카에 사용하는 데이터 형식이 무엇이든 간에 사용할 수 있는 커넥터는 영향을 받지 않음
- 많은 소스와 싱크는 스키마를 가지고 있음
  - 소스에서 데이터와 함께 스키마를 읽어서 저장한 후 호환성을 검증하거나 싱크 데이터베이스의 스키마를 업데이트 하는데 사용할 수 있음
### 변환
- 데이터 파이프라인 구축하는데는 ETL 방식과 ELT 방식이 있음
- ETL
  - 파이프라인 통과하는 데이터에 변경을 가하는 작업까지도 담당함
  - 데이터를 수정한 뒤 다시 저장할 필요가 없기 때문에, 시간과 공간을 절약할 수 있음
  - 파이프라인에서 데이터의 변환이 일어나기에, 파이프라인의 하단에서 데이터를 처리하고자 할때 손쓸 방법이 없음
- ELT
  - 대상 시스템에 전달되는 데이터가 원본 데이터와 최대한 비슷하도록 최소한의 변환만을 수행함
  - 대상 시스템이 raw data를 받아서 모든 필요한 처리를 다 수행함
### 보안
- 카프카는 소스에서 카프카로 데이터를 보내거나 카프카에서 싱크로 데이터를 보내는 데이터 전송 과정에서 데이터 암호화를 지원함
- SASL을 사용한 인증과 인가 역시 지원함
- 허락받지 않는 접근 내역을 추적하는 감사 로그도 지원
### 장애처리
- 이전 시점으로 돌아가서 에러를 복구할 수 있음
### 결합과 민첩성
- 데이터 파이프라인을 구현할 때, 데이터 원본과 대상을 분리할 수 있어야 함
  - 임기응변 파이프라인
    - 커스텀 파이프라인
  - 메타데이터 유실
    - 파이프라인이 스키마 메타데이터를 보존하지 않고 스키마 진화 역시 지원하지 않으면, 소스 쪽에서 데이터 생성 소프트웨어와, 싱크에서 사용하는 소프트웨어가 강하게 결합됨
    - 스키마 정보가 없기에, 두 소프트웨어 모두 데이터를 파싱하는 방법을 알아야함
  - 과도한 처리
    - 파이프라인에서 과도한 처리를 하면, 하단에서 처리할때 선택지가 남지 않게 됨
    - 애플리케이션의 요구 조건이 변경될 때마다 파이프라인도 변경해줘야 함
## 카프카 커넥트 vs 프로듀서/컨슈머
- 카프카 커넥트 : 카프카와 다른 데이터 저장소 사이에 확장성과 신뢰성을 가지면서 데이터를 주고받을 수 있는 수단을 제공함
  - 커넥트 플러그인(데이터 이동을 담당)을 개발하고, 실행하기 위한 API를 제공함
  - 커넥트는 워커 프로세스들의 클러스터 형태로 실행됨
  - 커넥터는 대용량의 데이터 이동을 병렬화해서 워커의 유휴 자원을 효울적으로 활용하기 위해 태스크를 추가로 실행시킴
## 카프카 커넥트 실행하기
코드 참고
p.236 ~p.252

## 카프카 커넥트: 좀 더 자세히 알아보기
- 커넥트를 사용할려면, 워커 클러스터를 실행시킨 뒤 커넥터를 생성하거나 삭제해줘야 함

### 커넥터와 태스크
- 커넥터 플러그인은 커넥터 API를 구현함
  - 커넥터 :
    - 커넥터에서 몇 개의 태스크가 실행되야 하는지 결정함
    - 데이터 복사 작업을 각 태스크에 어떻게 분할해 줄지 결정함
    - 워커로부터 태스크 설정을 얻어와서 태스크에 전달해줌
  - 태스크 :
    - 데이터를 실제로 카프카에 넣거나 가져오는 작업을 담당함
    - 모든 태스크는 워커로부터 컨텍스트를 받아서 초기화됨
  - 워커 :
    - 커넥터와 태스크를 실행시키는 역할을 맡는 컨테이너 프로세스임
    - HTTP 요청을 처리하고, 커넥터 설정을 내부 카프카 토픽에 저장, 커넥터와 태스크를 실행시키고, 적절한 설정값을 전달해줌
    - 워커의 이상을 감지해 태스크를 다른 워커에 재할당함
    - 모든 워커 간에 부하가 균형이 잡히도록 커넥터와 태스크를 할당해줌
    - 커넥터와 태스크는 데이터 이동을 맡음, 워커는 REST API, 설정관리, 신뢰성,고가용성, 규모 확장성, 부하 분산을 담당함
  - 컨버터 및 커넥트 데이터 모델 :
    - 카프카 커넥터 API에는 데이터 API가 포함되어 있음
      - 이 API는 데이터 객체와 이 객체의 구조를 나타내는 스키마를 모두 다룸
    - 소스 커넥터는 데이터 API를 사용해서 데이터 객체를 생성하는 방법을 알고 있음
      - 컨버터가 커넥트 워커가 이 객체들을 카프카에 쓸때 선택하게 해줌
    - 싱크 커넥터 :
      - 커넥트 워커는 카프카로부터 레코드를 읽어온 뒤, 설정된 컨버터를 사용해서 읽어 온 레코드를 카프카에 저장된 형식 레코드로 변환함
      - 이렇게 변환된 데이터는 다시 싱크 커넥터에 전달되어 최종적으로 대상 시스템이 쓰임
  - 오프셋 관리 :
    - 워커 프로세스가 커넥터에 제공하는 편리한 기능 중 하나..
### 카프카 커넥트의 대안
- 다른 데이터 저장소를 위한 수집 프레임워크
- GUI 기반 ETL 툴
- 스트림 프로세싱 프레임워크
    
