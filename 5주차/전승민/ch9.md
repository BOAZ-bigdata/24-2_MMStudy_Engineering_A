# 데이터 파이프라인 구축하기
- 카프카는 데이터 파이프라인의 다양한 단계 사이에 있어 매우 크고 안정적인 버퍼 역할을 함
- 데이터를 읽는 쪽과 쓰는 쪽을 분리함으로써 하나의 원본에서 가져온 동일한 데이터를 여러 조건을 가진 시스템에게 보낼 수 있음
- 데이터파이프라인을 이렇게 분리할 수 있는 것은 신뢰성, 보안성, 효율성과 함께 카프카가 데이터파이프라인에 적합한 이유임

## 데이터 파이프라인 구축 시 고려사항
- 적시성
  - 좋은 데이터 통합 시스템은 각각의 데이터 파이프라인에 대해 서로 다른 적시성 요구 조건을 지원함
  - 업무에 대한 요구 조건이 변경되었을 때도 이전하기가 쉬움
  - 확장성과 신뢰성을 보유한 저장소를 갖춘 스트리밍 데이터 플랫폼으로서 카프카는 실시간으로 작동하는 파이프라인부터 ~ 배치 작업에 이르는 모든 작업에 사용될 수 있음
  - 쓰는 쪽과 읽는 쪽 사이의 시간적 민감도에 대한 요구 조건을 분리시키는 거대한 버퍼로 생각해야 함
    - 쓰는 쪽에서는 실시간으로 쓸 수 있지만, 읽는 쪽에서는 배치 단위로 읽을 수 있으며, 그 반대도 가능함
    - 데이터의 소비 속도가 온전히 읽는 쪽에 의해 결정 되기에, 카프카 자체에서 응답을 늦춰 백프레셔를 적용하는 것임
    - cf) 백프레셔
      - 시스템에서 메시지 처리 속도보다 메시지 생성 속도가 빠를 때 발생하는 문제
- 신뢰성
  - 전달 보장을 고려해야함
  - 데이터 유실을 허용하는 시스템도 있지만, 대부분은 최소 한 번 보장을 요구하기에, 목적지에 발생한 이벤트가 모두 도착해야함
  - 원본 시스템에서 발생한 모든 이벤트가 유실도, 중복도 없이 목적지에 도착해야함
  - 카프카는 자체적으로 최소 한 번 전달을 보장하고 있음
    - 트랜젝션 모델, 고유 키를 지원하는 외부 데이터 저장소와 결합했을때, '정확히 한 번'까지도 보장이 가능함
  - 많은 엔드포인트들이 '정확히 한 번' 전달을 보장하는 데이터 저장소이기에, 카프카 역시 이를 보장할려함
  - 카프카 커넥트 API가 오프셋을 다룰 때 외부 시스템과의 통합을 지원하는 API를 지원하기때문에, '정확히 한 번' 전달을 보장하는 파이프라인 구축하기 위한 커넥터 개발이 쉬워짐
- 처리율
  - 매우 높은 처리율을 가질 수 있도록 확장이 가능해야 함
  - 카프카는 쓰는 쪽과 읽는 쪽 사이에서 버퍼 역할을 하기에, 프로듀서의 처리율과 컨슈머의 처리율을 묶어서 생각하지 않아도 됨
  - 프로듀서 처리율이 더 커지면, 컨슈머가 따라 잡을 때까지 카프카에 누적되기에, 복잡한 백프레셔 메커니즘을 개발할 필요가 없음
  - 카프카는 독립적으로 프로듀셔나 컨슈머를 추가함으로써 확장이 가능함
  - 카프카 커넥트 API는 작업을 병렬화하는데 초점을 두기에, 시스템 요구 사항에 따라 스케일 아웃을 수행함
- 데이터 형식
  - 데이터 파이프라인에서 가장 중요하게 고려할 것은 서로 다른 데이터 형식과 자료형을 적절히 사용하는 것임
  - 카프카 자체와 커넥트 API는 데이터 형식에 완전히 독립적임
    - 카프카 커넥트는 자료형과 스키마를 포함하는 고유한 인메모리 객체를 가지는데, 어떠한 형식으로도 저장될 수 있도록 장착 가능한 컨버터 지원함
    - => 카프카에서 사용하는 데이터 형식이 무엇이든 간에 사용할 수 있는 커넥터는 영향을 받지 
  - 많은 소스와 싱크는 스키마를 가지고 있음
    - 소스에서 데이터와 스키마를 읽어와 저장 후 호환성을 검증하거나, 싱크 데이터베이스의 스키마를 업데이트를 하는 데도 사용할 수 있음
  - 카프카의 데이터를 외부 시스템에 쓸 경우, 싱크 커넥터가 외부 시스템에 쓰여지는 데이터 형식을 책임짐
- 변환
  - 
