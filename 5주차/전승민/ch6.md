# 카프카 내부 메커니즘
- 카프카 내부 작동 방식을 알고 있으면 트러블슈팅을 하거나, 카프카가 실행되는 방식을 이해하는데 도움이 됨

## 클러스터 맴버십
- 현재 클러스터의 맴버인 브로커들의 목록을 유지하기 위해 아파치 주키퍼를 사용함
- 각 브로커는 브로커 설정 파일에 정의 되었거나, 자동으로 생성된 고유한 식별자를 가짐
- 브로커 프로세스는 시작될 때마다 주키퍼에 Ephemeral 노드의 형태로 ID를 등록함
- 컨트롤러를 포함한 카프카 브로커들과 몇개의 생태계들은 브로커가 등록되는 주키퍼의 /brokers/ids 경로를 구독함
  - 브로커가 추가되거나 제거될 때마다 알림을 받음
  - 동일한 ID를 가진 다른 브로커를 시작하면 에러가 발생함
- 브로커와 주키퍼 간의 연결이 끊어질 경우, 브로커가 시작될때 생성한 Ephemeral 노드는 자동으로 주키퍼에서 삭제됨
  - 브로커가 정지하면, 브로커를 나타내는 ZNode 역시 삭제되지만, 브로커의 ID는 다른 자료구조에 남게됨
  - 특정한 브로커가 완전히 유실되어 동일 ID를 갖는 새로운 브로커가 투입될 경우, 이전 브로커의 토픽과 파티션을 할당 받음

## 컨트롤러
- 일반적인 카프카 브로커의 기능에 더해, 파티션 리더를 선출하는 역할을 추가적으로 수행함
- 클러스터에서 가장 먼저 시작되는 브로커는 주키퍼의 /controller에 Ephemeral 노드를 생성함으로써 컨트롤러가 됨
  - 다른 브로커들 역시 시작할 때 노드를 생성할려하지만, 이미 존재해졌다는 것을 알게됨
- 브로커들은 주키퍼의 컨트롤러 노드에 뭔가 변동이 생겼을 때 알림을 받기 위해, 이 노드에 와치를 설정함
- => 클러스터 안에 한 번에 단 한 개의 컨트롤러만 보장하게 됨

  
- 컨트롤러 브로커가 멈추거나 주키퍼와의 연결이 끊어지면, Ephemeral 노드는 삭제됨
- 컨트롤러가 사용하는 주키퍼 클라이언가 지정된 시간보다 오랫동안 주키퍼에 하트비트를 전송하지 않는 것도 이에 해당함
  - 클러스터안의 다른 브로커들은 와치를 통해 컨트롤러가 삭제된것을 알아차리고, 주키퍼에 컨트롤러 노드를 생성하려고 시도함
  - 주키퍼에 가장 먼저 새로운 노드 생성에 성공한 브로커가 다음 컨트롤러가 됨
  - 브로커는 새로운 컨트롤러가 생성될때 마다 주키퍼의 조건적 증가 연산에 의해 증가된 'epoch값'을 전달받게 됨
  - 현재 ephoch값을 알기에, 브로커는 현재 ephoch값보다 더 낮은 경우 이 메시지를 무시함
    - 컨트롤러가 브로커가 오랫동안 가비지 수집 때문에 멈춘 사이 주키퍼 사이의 연결이 끊어지면 새 컨트롤러가 선출될 수도 있기 때문
- 브로커가 컨트롤러가 되면, 주키퍼로부터 최신 레플리카(데이터의 내구성과 가용성을 보장함) 상태 맵을 읽음
  - 비동기 API를 사용해서 수행되며, 여러 단계로 나눠 주키퍼로 보내기에 지연을 줄임
- 브로커가 클러스터를 나가면, 컨트롤러는 해당 브로커가 맡은 파티션에 대해 새로운 브로커를 할당함
- 새 브로커는 클라이언트로부터 쓰기, 읽기 수행하고, 파티션들은 메시지를 복제하기 시작함
- => 컨트롤러는 브로커가 추가되거나 삭제될때 파티션과 레플리카 중에서 리더를 선출할 책임을 짐,
- => 컨트롤러는 서로 다른 2개의 브로커 자신이 현재 컨트롤러라 생각하는 것을 방지하기 위해 에포크 번호를 사용함

## 카프카의 새로운 래프트 기반 컨트롤러
- KRaft기반 컨트롤러가 생김
- 컨트롤러가 주키퍼에 메타데이터를 쓰는 작업은 동기적이지만, 브로커 메시지를 보내거나 받는 과정은 비동기적임
- 데이터 부일치가 발생함
- 컨트롤러가 재시작할때마다 주키퍼로부터 모든 브로커와 파티션에 대한 메타 데이터를 읽어와야함
- 읽은 메타데이터들을 모든 브로커로 전송함 -> 병목 현상이 발생함
- 주키퍼는 그 자체로 분산 시스템이기에, 개발자들이 학습해야함 ...
- 이런 문제점들을 고려하여 주키퍼 기반 컨트롤러를 교체하는 쪽을 선택함
- 새로운 컨트롤러는 카프카 그 자체에 사용자가 상태를 스트림으로 나타내도록 로그 기반 아키텍처를 도입함
  - 다슈의 컨슈머 사용해 최신 상태를 따라 잡음
  - 로그는 이벤트 사이에 명확한 순서를 부여하고 컨슈머들이 항상 하나의 타임라인을 따르도록 설계함
  - 새로운 아키텍처에서 컨트롤러 노드들은 메타데이터 이벤트 로그를 관리하는 래프트 쿼럼이 됨
  - 주키퍼에 저장되어 있는 모든 정보들이 여기에 저장됨
- 래프트 알고리즘을 사용하면, 컨트롤러 노드들은 외부 시스템에 의존하지 않고, 자체적으로 리더를 선출할 수 있게 됨
  - 메타데이터 로그의 리더 컨트롤러는 '액티브 컨트롤럴'라고 불림
  - 이거는 브로커가 보내온 모든 RPC호출을 처리해야함
  - 팔로워 컨트롤러들은 리더를 복제하며, 장애에 준비를하고 있어야함
- 브로커 프로세스는 시작시 주키퍼가 아닌, 컨트롤러 쿼럼에 등록됨
- 종료되더라도 오프라인 상태지, 등록이 해지되는건 아님 (해제는 운영자에 의해 ...)
- 최신 상태를 유지하지 못하면 클라이언트 요청을 처리할 수 없음
- fenced state: 최신화되지못해, 리더 조차 인식 못하는 브로커를 말함
- 마이그레이션 : 기존의 카프카 데이터를 새로운 환경으로 옮기는 것을 말함
### 요약
  - Kraft 이후의 '브로커'는 카프카 프로세스가 맡을 수 있는 특정한 '역할'을 의미함
  - Kraft 이후의 '컨트롤러'는 동적 메타데이터를 저장하는 역할을 하는 카프카 프로세스를 말함
- Kraft 모드 사용법
  p.156 ~p.158 읽어보기

## 복제
- 복제는 카프카 아키텍처의 핵심임
- 복제는 장애에 대응하고, 카프카의 신뢰성과 지속성을 보장하는 방식이기 때문
- 카프카에 저장되는 데이터는 토픽을 단위로 해서 조직화됨
  - 각 토픽은 1개 이상의 파티션으로 분할되며
  - 각 파티션은 다시 다수의 레플리카를 가질 수 있음
  - 각 레플리카는 브로커에 저장되는데, 브로커는 수백 개에서 수천 개의 레플리카를 저장함
- 리더 레플리카
  - 각 파티션에서 리더 역할을 하는 레플리카
  - 일관성 보장을 위해, 모든 쓰기 요청은 리더 레플리카로 주어짐
  - 클라이언트들은 리더 레플리카나 팔로워로부터 레코드를 읽어올 수 있음
  - 팔로워 레플리카의 최신 상태를 확인함
- 팔로워 레플리카
  - 파티션에 속한 모든 레플리카 중에서 리더 레플리카를 제외한 나머지를 팔로워 레플리카라고 함
  - 팔로워는 클라이언트의 요청을 처리할 수 없음
  - 리더 레플리카의 메시지를 복제해 최신 상태를 유지함

- 아웃 오브 싱크 레플리카
  - 팔로워 레플리카가 일정 시간 이상 읽기 요청을 보내지 않거나, 읽기 요청을 보냈는데 최근 메시지를 못잡으면, 동기화가 풀린것으로 간주되는거
- 인 싱크 레플리카
  - 지속적으로 최신 메시지를 요청하고 있는 레플리카를 말함
- 팔로워 레플리카가 동기화가 풀린 것으로 판정될 때까지 걸리는 시간은 replica.lag.time.max.ms 설정 매개변수에 의해 결정됨
- 이렇게 허용될 수있는 랙의 양은 클라이언트의 작동이나 리더 선출 과정에 있어서의 데이터 보존에도 영향을 미침
- 선호 리더
  - 토픽이 처음 생성 되었을때 리더 레플리카였던 레플리카를 가리킴
  - 파티션이 처음 생성되던 시점에서는 리더 레플리카가 모든 브로커에 걸쳐 균등하게 분포되기 때문에 선호라고 부름
  - 클러스터 내의 모든 파티션에 대해 선호 리더가 실제 리더가 되면, 부하가 브로커 사이에 균등하게 분배됨
## 요청 처리
- 카프카 브로커는 클라이언트, 파티션 레플리카, 컨트롤러가 파티션 리더에게 보내는 요청을 처리하는게 대부분임
- 카프카는 TCP로 전달되는 이진 프로토콜을 가지고 있음
- 클라이언트가 연결하고, 요청하면, 브로커가 요청 처리하고 응답함
- 이때 메시지 순서가 보장되기에, 카프카를 메시지 큐로 활용할 수 있음
- 브로커는 연결을 받는 각 포트별로 업섹터 스레드를 하니씩 실행시킴
  - 업섹터 스레드 : 연결을 생성하고 들어온 요청을 프로세서 스레드에 넘겨 처리하도록 함
  - 네트워크 스레드 : 클라이언트로부터 들어온 요청을 받아 요청 큐에 넣고, 응답 큐에서 응답을 가져와 클라이언트로 전달함
  - 컨슈머의 경우 브로커 쪽에 데이터가 준비되었을 때에만 응답을 보낼 수 있고, 어드민 클라이언트의 경우 토픽 삭제가 진행중인 상황에서만 응답을 보냄
<img width="872" alt="스크린샷 2024-08-12 오후 1 36 18" src="https://github.com/user-attachments/assets/737ad7ef-b293-4d6d-892e-d12d11a582be">

- 클라이언트의 요청 유형
  - 쓰기 요청 : 메시지를 쓰고 있는 프로듀서가 보낸 요청
  - 읽기 요청 : 브로커로부터 메시지를 읽어오고 있는 컨슈머나 팔로워 레플리카가 보낸 요청
  - 어드민 요청 : 토픽 생성이나 삭제와 같이 메타데이터 작업을 수행중인 어드민 클라이언트가 보낸 요청
- 클라이언트는 메타데이터 요청이라 불리는 또 다른 유형의 요청을 사용함
  - 클라이언트가 다루고자 하는 토픽들의 목록을 포함함
  - 서버는 이 토픽에 대해 응답을 해줌
  - 메타데이터 요청은 아무 브로커에 보내도 상관이 없음 (브로커들이 이런 정보에 대해 캐시를 가지고 있기 때문..)
- 쓰기 요청
  - acks = 1 : 리더만이 메시지를 받았을때
  - acks = all : 모든 인-싱크 레플리카들이 메시지를 받았을때
  - acks = 0 : 메시지가 보내졌을 때, 브로커의 응답을 기다리지 않음
  - 파티션의 리더 레플리카를 가진 브로커가 해당 파티션에 대한 쓰기 요청을 받으면, 유효성 검증부터 함
  - 이후 브로커가 새 메시지들을 로컬 디스크에 적음
- 읽기 요청
  - 클라이언트는 브로커에 메시지 보내달라고 요청함
  - 각 파티션에 대해 브로커가 리턴할 수 있는 최대 데이터의 양 역시 지정함
  - 클라이언트는 브로커가 되돌려준 응답을 담을 수 있을 정도로 충분히 큰 메모리를 할당해야하기 때문
  - 카프카는 클라이언트에게 보내는 메시지에 제로카피 최적화를 적용하는것으로 유명함
    - 파일에서 읽어온 메시지를 중간 버퍼를 거치지 않고, 바로 네트워크 채널로 보내는 것임
    - 데이터베이스와의 가장 큰 차이점
    - 이 방식으로 데이터를 복사하고 메모리 상에 버퍼를 관리하기 위한 오버헤드가 사라지며, 성능이 향상됨
  - 브로커는 데이터 양의 하한도 정할 수 있음
    - 충분히 축적된 후 결과를 리턴하도록 함
    - CPU와 네트워크 사용량을 감소시키는데 좋음
  
- 카프카 프로토콜은 계속 진화중임
- 카프카의 기본 저장 단위는 파티션 레플리카
- 계층화된 저장소를 가짐
  - 계층별로 사용자는 서로 다른 보존 정책을 설정할 수 있음
### 파티션 할당
- 사용자가 토픽을 생성하면, 카프카는 이 파티션을 브로커 중 하나에 할당함
- 레플리카들을 브로커 간에 고르게 분산시킴
- 브로커에 랙 정보가 설정되어 있다면, 가능한 각 파티션의 레플리카들을 서로 다른 랙에 할당함
  - 랙 전체가 장애가 발생해도,파티션 전체가 사용 불능에 빠지는 사태를 방지할 수 있음

### 파일 관리
- 보존은 카프카에 있어서 중요한 개념
- 카프카 운영자는 각각의 토픽에 대한 보존 기한을 설정할 수 있음
- 큰 파일 삭제는 오래걸리기에, 하나의 파티션을 여러 개의 세그먼트로 분할하기로 함
- 세그먼트도 한도가 차면, 새 세그먼트를 생성함
  - 현재 쓰여지는 세그먼트를 액티브 세그먼트라고 함
  - 이거는 어떠한 경우에도 삭제되지 않음
  - 각 세그먼트는 하나의 데이터 파일 형태로 저장됨
  - 파일 안에는 카프카의 메시와 오프셋이 저장됨
### 압착
- 카프카는 설정된 기간 동안만 메시지를 저장하며, 보존 시간이 지난 메시지들은 삭제함
- 두 가지 보존 정책을 허용
  - 삭제 보존 정책
    - 지정된 보존 기한보다 더 오래 된 이벤트들을 삭제함
  - 압착 보존 정책
    - 토픽에서 각 키의 가장 최근값만 저장하도록 함
    - 애플리케이션이 키와 밸류를 모두 포함하는 이벤트를 생성하는 토픽의 경우 압착 설정을 잡아주는 것이 합리적임
    - 토픽 키 값이 null인 경우 메시지 압착은 실패임
  - 이 정책은 토픽이 지나치게 크게 자라나거나, 일정 기한이 지난 레코드들을 삭제할때 활용함
### 압착 작동원리
- 클린 : 이전에 압착된 적이 있었던 메시지들이 저장됨, 하나의 키마다 하나의 값만을 포함함
- 더티 : 마지막 압착 작업 이후 메시지들이 저장됨
- 각 스레드는 전체 파티션 크기 대비 더티 메시지의 비율이 가장 높은 파티션을 골라 압착한 뒤 클린 상태로 만듬
 
### 삭제된 이벤트
- 최근 메시지 조차도 남기지 않고 삭제할려면, 키 값에 null을 다 해주면 됨
- 컨슈머는 톰스톤 메시지를 보고 삭제된 것을 알게됨
- 특정 기간이 지나면 클리너 스레드가 톰스톤 메시지를 삭제하며, 키 역시 카프카 파티션에서 완전히 삭제됨
- 카프카는 토픽 내용물의 50% 이상이 더티 레코드인 경우에만 압착을 시작함
- 토픽을 너무 지나치게 자주 압착하지 않으면서, 더티 레코드가 너무 많지 않게 하는거임
- 운영자에 의해 조절이 가능함

