# 6장 카프카 내부 메커니즘
핵심: 카프카 컨트롤러 / 카프카에서 복제가 작동하는 방식/ 카프카가 프로듀서와 컨슈머의 요청을 처리하는 방식 / 카프카가 저장을 처리하는 방식

-> 카프카를 튜닝할 때 작동하는 메커니즘을 알고 있으면 좋으니

## 클러스터 멤버십
카프카는 현재 클러스터의 멤버인 브로커들의 목록을 유지하기 위해 아파치 주키퍼를 사용함

브로커들은 고유한 식별자를 가지고 있고 브로커 프로세스는 시작될 때마다 주키퍼에 Ephemeral 노드의 형태로 ID를 등록한다. 

브로커와 주키퍼 간의 연결이 끊어질 경우 브로커가 시작될 때 생성한 Ephemeral 노드는 자동으로 주키퍼에서 삭제된다.

## 컨트롤러
카프카 브로커의 기능에 더해서 파티션 리더를 선출하는 역할을 추가적으로 맡는다. 

`클러스터에서 가장 먼저 시작되는 브로커`가 컨트롤러가 됨

### KRaft
주키퍼 기반 컨트롤러부터 탈피해서 래프트 기반 컨트롤러 쿼럼으로 옮김

바꾼 이유?
- 현재의 모델이 카프카에 필요로 하는 파티션 수까지 확장할 수 없다는 결론이 나오게 됨
    - 컨트롤러가 주키퍼에 메타데이터를 쓰는 작업은 동기적 / 브로커 메시지를 보내느 작업은 비동기적
    - 컨트롤러가 재시작될 때마다 주키퍼로부터 모든 브로커와 파테션에 대한 메타데이터를 읽어오고, 이 메타데이터를 모든 브로커로 전송함
    -> 병목현상 발생

새로운 컨트롤러의 핵심 아이디어는 : 카프카 그 자체에 사용자가 상태를 이벤트 스트림으로 나타낼 수 있도록 하는 로그 기반 아키텍처를 도입

래프트 알고리즘을 사용함으로써, 컨트롤러 노드들은 외부 시스템에 의존하지 않고 자체적으로 리더를 선출할 수 있게 함. 

브로커 프로세스는 시작시 주키퍼가 아닌, 컨트롤러 쿼럼에 등록하고 이를 운영자가 해제하지 않는 한 이를 유지한다. 브로커가 종료되더라도 오프라인 상태로 들어가는 것이지, 등록은 여전히 유지됨.

현재 KRaft 도입 후 분리
- 컨트롤러: 카프카 클러스터의 동적 메타데이터를 저장하는 역할
- 브로커: 카프카 데이터를 저장하는 역할

-> KRaft 이전의 브로커는 카프카 프로세스와 동의어지만, 그 이후의 브로커는 카프카 프로세스가 맡을 수있는 특정한 '역할' 을 의미하는 용어

-> 이전의 컨트롤러는 브로커 중에서 파티션 리더를 결정하는 역할을 맡는 특별한 브로커지만 이 후로는 동적 메타데이터르르 저장하는 역할을 하는 카프카 프로세스
 
#### 즉, KRaft 이전인지 이후인지 잘 파악하는 것이 중요하다.

## 복제
카프카 아키텍처의 핵심이다. 분산되고 분할되고 복제된 커밋 로그 서비스. 
카프카에 저장되는 데이터는 토픽을 단위로 해서 조직화, 가가 토픽은 1개 이상의 파티션으로 분할되고 각 파티션은 다수의 레플리카를 가짐

- 리더 레플리카: 각 파티션에 리더 역할을 하는 레플리카가 하나씩 있다. 모든 쓰기 요청은 리더 레플리카로 주어짐
- 팔로워 레플리카: 리더 레플리카를 제외한 나머지를 팔로워 레플리카라고 하고, 리더 레플리카로 들어오느 최근 메시지들을 복제함으로써 최신 상태를 유지

## 요청 처리
카프카 브로커가 하는 일의 대부분은 클라이언트, 파티션 레플리카, 컨트롤러가 파치션 리더에게 보내느 요청을 처리하는 것.

언제나 클라이언트가 연결을 시작하고 요청을 전송하며, 브로커는 요청을 처리하고 클라이언트로 응답을 보낸다. 특정 클라이언트가 브로커로 전송한 모든 요청은 브로커가 받은 순서대로 처리

즉, 카프카가 저장하는 메시지는 순서가 보장되며 카프카를 메시지 큐로 사용할 수도 있는 것이다. 

## 물리적 저장소
카프카의 기본 저장 단위는 파티션 레플리카 / 파티션은 서로 다른 브로커들 사이에 분리될 수 없고 같은 브로커의 서로 다른 디스트에 분할 저장되는 것조차 불가능.

따라서 파티션의 크기는 특정 마운트 지점에 사용 가능한 공간에 제한을 받는다고 볼 수 있다.

카프카가 데이터를 저장하기 위해 사용 가능한 디렉토리들을 어떻게 활용하는지 알아보자.

1) 데이터가 클러스터 안의 브로커, 브로커 안의 디렉토리에 할당되는 방식
2) 브로커가 파일을 관리하는 방법
3) 파일 내부로 초점을 옮겨 파일과 인덱스의 형식에 대해
4) 카프카를 장시간용 데이터 저장소로 사용할 수있게 해주는 고급 기능인 로그 압착 기능

### 계층화된 저장소
카프카는 현재 대량의 데이터를 저장하기 위한 목적으로 사용됨

문제 : 
- 파티션별로 저장 가능한 데이터에 한계가 있음.
- 디스크와 클러스터 크기는 요구 조건에 의해 결정되는데 지연과 처리량이 . 주 고려사항일 경우 필요 이상으로 커져서 비용이 높아짐
- 파티션의 크기가 클수록 클러스터의 탄력성이 줄어들기 때문에 유연한 옵션을 활용할 . 수있게 최대한의 탄력성을 가지는 것이 요즘 아키텍쳐 설계의 추세

계층화된 저장소에서는 카프카 클러스터의 저장소를 로컬과 원격 두 계층으로 나눈다. 

로컬 저장소는 원격 저장소에 비해 지연이 훨씬 짧고, 지역에 민감한 애플리케이션들은 로컬 계층에 저장되어 있는 최신 레코드를 읽어와서 페이지 캐시를 효율적으로 활용하는 카프카의 메커니즘에 문제 없이 작동

빠진 처리 결과를 메꾸는 작업 또는 장애에서 복구되고 있는 애플리케이션들은 더 오래된 데이터를 필요로 하므로 원격 계층에 있는 데이터가 전달됨

즉, `계층화된 저장소 기능`은 무한한 저장 공간, 더 낮은 비용, 탄력성뿐만 아니라 `오래 된 데이터와 실시간 데이터를 읽는 작업을 분리시키는 기능` 존재

### 파티션 할당
사용자가 토픽을 생성하면, 카프카는 우선 이 파티션을 브로커 중 하나에 할당.

파티션 할당 목표
1. 레플리카들을 가능한 한 브로커 간에 고르게 분산시킨다
2. 각 파티션에 대해 각각의 레플리카는 서로 다른 브로커에 배치되도록 한다. 
3. 만약 브로커에 랙 정보가 설정되어 있다면 가능한 한 각 파티션의 레플리카들을 서로 다른 랙에 할당
-> 이렇게 해야 하나의 랙 전체가 작동 불능에 빠지더라도 전체가 사용 불능에 빠지는 사태를 방지할 수 있다.

### 파일 관리
보존은 카프카에 있어서 중요한 개념인데, 카프카는 영구히 데이터를 저장하지도, 데이터를 지우기 전에 모든 컨슈머들이 메시지를 읽어갈 . 수있도록 기다리지 않는다.

-> 카프카 운영자는 각각의 토픽에 대해 보존 기한을 설정할 수 있다.

현재 쓰여지고 있는 세그먼트를 액티브 세그먼트라 부르는데 이거는 어떠한 경우에도 삭제되지 않는다.

세그먼트가 닫히기 전까지는 데이터를 삭제할 수 없다,

### 파일 형식
각 세그먼트는 하나의 데이터 파일 형태로 저장됨. 파일 안에는 카프카의 메시지돠 오프셋이 저장됨. 

각 레코드에는 거의 오버헤드가 없고 대부분의 시스템 정보는 배치 단위에서 저장되어 있다는 점에 주목하자.

### 인덱스
카프카는 타임스탬프와 메시지 오프셋을 매핑하는 또 다른 인덱스를 가지고 있다. 인덱스는 타임스탬프르르 기준으로 메시지를 찾을 때 사용되고 인덱스들 역시 세그먼트 단위로 분할된다.

### 압착
1) 삭제 보존 정책

지정된 보존 기한보다 더 오래 된 이벤트들을 삭제

2) 압착 보존 정책

토픽에서 각 키의 가장 최근값만 저장하도록 한다

